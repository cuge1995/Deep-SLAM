# Deep-SLAM
a list of papers, code, and other resources focus on deep learning SLAM sysytem

## Camera
* DROID-SLAM: Deep Visual SLAM for Monocular, Stereo, and RGB-D Cameras [[code]](https://github.com/princeton-vl/DROID-SLAM)[[paper]](https://arxiv.org/pdf/2108.10869)
* Deeptam: Deep tracking and mapping [[no code]]()[[paper]](http://openaccess.thecvf.com/content_ECCV_2018/papers/Huizhong_Zhou_DeepTAM_Deep_Tracking_ECCV_2018_paper.pdf) `ECCV 2018`
* Beyond tracking: Selecting memory and refining poses for deep visual odometry [[no code]]()[[paper]](https://openaccess.thecvf.com/content_CVPR_2019/papers/Xue_Beyond_Tracking_Selecting_Memory_and_Refining_Poses_for_Deep_Visual_CVPR_2019_paper.pdf) `CVPR 2019`
* Sequential adversarial learning for self-supervised deep visual odometry [[no code]]()[[paper]](https://openaccess.thecvf.com/content_ICCV_2019/papers/Li_Sequential_Adversarial_Learning_for_Self-Supervised_Deep_Visual_Odometry_ICCV_2019_paper.pdf) `ICCV 2019`
* D2VO: Monocular Deep Direct Visual Odometry [no code]()[[paper]](http://ras.papercept.net/images/temp/IROS/files/2025.pdf) `IROS 2020`
* Deepfactors: Real-time probabilistic dense monocular slam [no code]()[[paper]](https://arxiv.org/pdf/2001.05049) `IEEE Robotics and Automation Letters, 2020`
* Self-supervised deep visual odometry with online adaptation [[no code]]()[[paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Li_Self-Supervised_Deep_Visual_Odometry_With_Online_Adaptation_CVPR_2020_paper.pdf) `CVPR 2020`
* Voldor: Visual odometry from log-logistic dense optical flow residuals [[code]](https://github.com/htkseason/VOLDOR)[[paper]](http://openaccess.thecvf.com/content_CVPR_2020/papers/Min_VOLDOR_Visual_Odometry_From_Log-Logistic_Dense_Optical_Flow_Residuals_CVPR_2020_paper.pdf) `CVPR 2020`
* Generalizing to the Open World: Deep Visual Odometry with Online Adaptation [[no code]][[paper]](https://openaccess.thecvf.com/content/CVPR2021/papers/Li_Generalizing_to_the_Open_World_Deep_Visual_Odometry_With_Online_CVPR_2021_paper.pdf) `CVPR 2021`
* Unsupervised monocular visual odometry based on confidence evaluation [[no code]][[paper]](https://ieeexplore.ieee.org/abstract/document/9345430/) `IEEE Transactions on Intelligent Transportation Systems, 2021`




## LiDAR
* Lo-net: Deep real-time lidar odometry [[no code]][[paper]](https://openaccess.thecvf.com/content_CVPR_2019/papers/Li_LO-Net_Deep_Real-Time_Lidar_Odometry_CVPR_2019_paper.pdf) `CVPR 2019`
* Self-supervised Visual-LiDAR Odometry with Flip Consistency [[no code]][[paper]](https://openaccess.thecvf.com/content/WACV2021/papers/Li_Self-Supervised_Visual-LiDAR_Odometry_With_Flip_Consistency_WACV_2021_paper.pdf) `WACV 2021`
